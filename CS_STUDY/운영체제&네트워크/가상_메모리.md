# 가상 메모리



## Page fault와 교체 알고리즘 

### 💡 메모리 관리 방법

---

1. 현대 메모리는 `Paging` 기법을 채택
2. 하드 디스크를 `Swap area` 로 활용한다.
3. `MMU` `TLB` 와 같은 하드웨어의 지원을 받아 `Page Table` 을 확인하고 메모리를 참조한다.

### 💡 가상 메모리

---

<img src="가상_메모리.assets/Untitled.png" alt="Untitled" style="zoom: 33%;" />

하나의 프로세스는 물리 메모리와 Swap 공간에 분리되어 올라가 있다.

<img src="가상_메모리.assets/Untitled%201.png" alt="Untitled" style="zoom:33%;" />

- 가상메모리 : 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법
  - 물리 메모리 + Swap 공간으로 분리된 메모리를 합쳐서 만든 가짜 메모리
  - 가상 메모리 주소 = 논리 주소

<img src="가상_메모리.assets/Untitled%202.png" alt="Untitled" style="zoom:33%;" />

Swap 공간 ( 디스크 ) 에 접근하는 것은 운영체제의 관할

### 가상 메모리 사용의 장점 (↔ 프로세스 전체를 메모리에 올릴 때)

1. 사용자 프로그램이 물리 메모리의 제약에서 벗어남
   - 필요한 부분만 물리 메모리에 올리기 때문에 사용자 프로그램이 물리 메모리보다 커져도 됨
2. 각 프로그램이 더 작은 메모리를 차지하기 때문에, 더 많은 프로그램을 동시에 수행(멀티태스킹)
3. 프로그램을 메모리에 올리고 swap 하는데 필요한 I/O 횟수가 줄어듦
   - I/O가 적게 일어나므로 효율 up

### 💡 요구 페이징

---

- 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 것이 아니라, 당장 사용될 페이지만을 올리는 방식
- 따라서 요구 페이징 기법에서는 특정 페이지에 대해 CPU의 요청이 들어온 뒤 해당 페이지를 메모리에 적재

<img src="가상_메모리.assets/Untitled%203.png" alt="Untitled" style="zoom: 50%;" />

- 가상 메모리 주소 → 물리 메모리 주소 변환 과정

<img src="가상_메모리.assets/Untitled%204.png" alt="Untitled" style="zoom:80%;" />

- page fault 의 과정
  1. MMU가 Trap 발생 (소프트웨어 인터럽트)
  2. CPU가 운영체제로 넘어감 → 운영체제의 page fault handler 실행
  3. 메모리의 빈 페이지 프레임 get ( 없으면 뺏어오기 replace )
     - Replacement Algorithm
       <img src="가상_메모리.assets/Untitled%205.png" alt="Untitled" style="zoom:33%;" />
       <img src="가상_메모리.assets/Untitled%206.png" alt="Untitled" style="zoom:33%;" />
       1. victim swap out
          - 쫓겨나는 희생양 `victim` 의 수정 사항 있으면?
            - 변경된 내용을 backing store (디스크)에 기록
       2. 요구된 page swap in
       3. page table에 해당 사항 기록
  4. 해당 페이지를 disk에서 메모리로 읽어오기
     1. disk I/O 요청하고, (disk의 작업 속도 느리기 때문에) 작업 중이던 프로세스 block 처리
     2. disk I/O 끝나면 인터럽트
     3. TLB에 주소 등록, page table에 해당 페이지 번호와 valid 표시
     4. block 상태였던 프로세스 ready queue에
     5. 프로세스가 다시 CPU를 잡고 running
  5. 아까 중단되었던 작업 계속

### 💡 Replacement Algorithm

---

#### 1. Optimal Algorithm

: 미래에 참조될 page를 모두 알고 있다고 가정 → Offline Algo

<img src="가상_메모리.assets/Untitled%207.png" alt="Untitled" style="zoom: 50%;" />

replace가 필요한 시점 ( 5 참조할 때 ) 에서,

가장 먼 미래에 참조될 page 4 를 victim으로 선정

→ page fault가 최소로 발생하는 방법 , 가장 좋은 성능의 Algo 기준이 된다.

### 2. FIFO Algorithm

: 미래를 모름 → 먼저 들어온 것을 먼저 내쫓음

<img src="가상_메모리.assets/Untitled%208.png" alt="Untitled" style="zoom:50%;" />

- FIFO Anomaly : 메모리 크기를 늘렸는데 성능이 더 나빠지는 (page fault ↑) 기이한 현상

### 3. LRU Algorithm

: 미래를 모름 → 가장 오래 전에 참조된 것을 지움. 가장 많이 사용되는 방법

<img src="가상_메모리.assets/Untitled%209.png" alt="Untitled" style="zoom:33%;" />

### 3. LFU Algorithm

: 미래를 모름 → 가장 적게 참조된 페이지를 쫓아냄

<img src="가상_메모리.assets/Untitled%2010.png" alt="Untitled" style="zoom:33%;" />

## Heap?, LFU , Clock Algorithm

![img.gif](가상_메모리.assets/img.gif)

![Untitled](가상_메모리.assets/Untitled%2011.png)

페이지 교체에서 뿐만 아니라, 캐싱 기법에서도 사용된다.

<img src="가상_메모리.assets/Untitled%2012.png" alt="Untitled" style="zoom: 50%;" />

### 캐싱 기법

- 한정된 빠른 공간(캐시)에 요청된 데이터를 저장해 두었다가 또 똑같은 요청이 들어오면 느린 저장장치에 접근하지 않고 빠른 캐시로부터 직접 서비스하는 방식
- 가상 메모리 페이징 시스템에서는한정된 빠른공간(=물리메모리, RAM), 느린 저장장치(=하드디스크, 백킹 스토어)
- paging system 외에도 cache memory, buffer caching(파일 시스템에 대한 read/write요청을 메모리에서 빠르게 처리하는 방식), web chaching(멀리있는 컴퓨터에 요청해서 이미 읽어온 웹페이지를 내 컴퓨터에 저장했다가 또다시 요청했을 때 빠르게 응답해줄 수 있음)등 다양한 분야에서 사용.

LRU(least recently used)

LFU(least frequently used)

위 두 알고리즘이 실제 paging system에서 가능할까??

불가능하다.

**페이지가 이미 메모리에 올라와 있는 경우 하드웨어적으로만 동작하기 때문에 OS가 처리할 시점의 정보가 부족함**

주소 변환은 하드웨어가 하고

운영체제는 모르기 때문이다.

LRU는 오랜 기간동안 사용되지 않은 페이지를 찾아야 하고

LFU는 참조 횟수가 가장 작은 페이지를 찾아야 한다.

- page fault가 발생했다.

그렇다면 운영체제에게 트랩이 발생하고

운영체제는 디스크에 내려가서 해당 페이지를 찾아서 메모리에 올릴 것이다.

이건 운영체제가 직접 개입하기 때문에 시간이나 횟수가 체크가 가능하다.

- page fault가 발생하지 않았다면???

하드웨어가 주소변환하고

해당 주소(페이지 테이블)에 가서 페이지 프레임을 알아내고

접근하면 끝이다.

위 과정에서

운영체제가 개입한 부분은 없다.

page fault가 나지 않으면

운영체제는 어떤 페이지가 몇번 사용되었는지 모른다.

그래서 LRU, LFU는 paging system에서는 실제적으로 사용이 안된다.

<img src="가상_메모리.assets/Untitled%2013.png" alt="Untitled" style="zoom:50%;" />

그래서 clock algorithm이라고 LRU 근사 알고리즘이 있다.

- 여러 명칭으로 불린다.**= Clock Algorithm** : 시계바늘이 이동하면서 알고리즘이 동작하는 방식이라서 이렇게 부름.**= Second chance Algorithm** : 기회를 한번 더 준다.**= NRU Algorithm(Not Recently Used)** : 최근에 사용되지 않은 페이지를 쫓아낸다.
- reference bit 이라는 것을 둬서, 이미 메모리에 존재하는 페이지가 참조되면 1로 표시한다. (이건 운영체제가 안하고 하드웨어가 합니다! )
- 그러면 페이지 폴트가 나서 쫓아내야 하는데, reference bit을 봤는데 1이면 적어도 한번은 참조가 됐구나 알고 쫓아내지 않고 비트만 0으로 바꾸고 다음껄 확인한다.

<img src="가상_메모리.assets/Untitled%2014.png" alt="Untitled" style="zoom:50%;" />

하드웨어적으로 조작이 가능한 reference bit가 붙는다.

이 비트는 최근에 참조된 페이지면 1 아니면 0이다.

포인터(시계 바늘)가 페이즈의 참조 비트들을 확인하면서 돌아간다.

참조 비트가 1이라면

아 이 페이지는 내가 한바퀴 돌기전에 사용이 되었구나 하면서 0으로 바꾸고 다음으로 간다.

참조 비트가 0이라면

아 이 페이지는 내가 한바퀴 돌고 왔는데도 사용이 안되었네??

그럼 너는 지금 교체 해야겠다 하면서 1로 바꾸면서 교체한다.

가장 오랜기간동안 사용되지 않은 페이지를 교체하는 것까지는 미치지 못하지만

그래도 한바퀴 돌 때 동안 사용되지 않은 페이지면 충분히 교체할만한 이유가 된다.

- 개선 : modified bit이 있다.
  읽기: reference bit만 1
  쓰기: 둘다 1
- modified bit은 어떤 페이지가 쫓겨날 때, 이 페이지의 modified bit이
- 0이면 수정이 안된애라, 그냥 지워도 된다.
- 1이면 적어도 한번은 내용은 수정한 애다. 그래서 쫓겨날때는 수정된 내용을 반영한 후에 지워야된다.
- **Clock algorithm의 개선** : modified bit이 1이면쫓아내지 말자.

## Allocation, Thrasing, Working-set , PFF - 이상훈

### Allocation

각 프로세스에 얼만큼의 페이지 프레임을 할당할 것인가

### Allocation의 필요성

1. 메모리 참조 명령어 수행시 명령어, 데이터 등 여러 페이지 동시참조
   - 명령어 수행을 위해 최소항 할당되어야 하는 프레임의 수가 있음
2. Loop를 구성하는 page들은 한꺼번에 allocate 되는 것이 유리함
   - 최소한의 allocation이 없으면 매 loop 마다 page fault

### Allocation Scheme

1. Equal allocation : 모든 프로세스에 똑같은 갯수 할당
2. Propertional allocation : 프로세스 크기에 비례하여 할당
3. Priority allocation : 프로세스의 priority에 따라 다르게 할당

### Global replacement(프로세스 간 경쟁)

1. Replace 시 다른 process에 할당된 frame을 빼앗아 올 수 있다
2. Process별 할당량을 조절하는 또 다른 방법이다
3. FIFO , LRU, LFU 등의 알고리즘을 global replacement로 사용시에 해당
4. Working set, PFF 알고리즘 사용

### Local replacement(프로세스 내부에서 대체)

1. 자신에게 할당된 frame 내에서만 replacement
2. FIFO, LRU, LFU 등의 알고리즘을 process 별로 운영시

### Thrashing

1. 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우 발생
2. page fault rate이 매우 높아짐
3. CPU utilization이 낮아짐
4. OS MPD(Multiprogramming degree)를 높여야 한다고 판단
5. 또 다른 프로세스가 시스템에 추가됨(higher MPD)
6. 프로세스 당 할당된 frame의 수가 더욱 감소
7. 프로세스는 page의 swap in / swap out으로 매우 바쁨
8. 대부분의 시간에 CPU는 한가함
9. 낮은 처리량

![70577700-19128800-1bef-11ea-8322-0f6e67d6334d.png](가상_메모리.assets/70577700-19128800-1bef-11ea-8322-0f6e67d6334d.png)

### Working-set Model

1. Locality of reference
   - 프로세스는 특정 시간동안 일정 장소만을 집중적으로 참조한다
   - 집중적으로 참조되는 해당 page들의 집함을 locality set이라 함
2. Working-set Model
   - Locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 Working set이라 정의함
   - Working set 모델에서는 process의 working set 전체가 메모리에 올라와 있어야 수행되고 그렇지 않을 경우 모든 frame을 반납한 후 swap out(suspend)
   - Thrashing을 방지함
   - Multiprogramming degree를 결정함

### Working-Set Algorithm

1. Working set의 결정
   - Woriking set window를 통해 알아냄
   - Window size 가 Δ인 경우
     시각 ti에서의 working set WS(ti)
     Time interval[ti- Δ,ti] 사이에 참조된 서로 다른 페이지들의 집합
   - Working set에 속한 page는 메모리에 유지, 속하지 않은 것은 버림
     (즉, 참조된 후 Δ 시간 동안 해당 page를 메모리에 유지한 후 버림 )

### PPF(Page-Fault Frequency) Scheme

1. page-fault rate의 상한값과 하한값을 둔다
   - Page fault rate이 상한값을 넘으면 frame을 더 할당한다
   - Page fault rate이 하한값 이하이면 할당 frame 수를 줄인다
2. 빈 frame이 없으면 일부 프로세스를 swap out
